# ...keep existing...
PERSIST_DIR=index
DATA_RAW_DIR=data/raw
DATA_CLEAN_DIR=data/clean
OLLAMA_CHAT_MODEL=llama3.1:8b
OLLAMA_EMBED_MODEL=nomic-embed-text
CHUNK_TOKENS=1000
OVERLAP_TOKENS=180
CHUNK_VERSION=v1   # bump when chunking logic changes to force re-index
RUN_INGEST_ON_START=false  # do not block startup; set true to run background update
RETR_USE_MMR=1        # Enable MMR diversity in retrieval (0=off, 1=on)
RETR_TOPN=30          # Candidate pool size for retrieval (20–50)
RETR_MMR_LAMBDA=0.6   # MMR lambda: 0=relevance, 1=diversity (try 0.5–0.7)

# Default top-k for Ask endpoint (number of context chunks injected)
ASK_TOP_K=8

# Timeout for Ollama HTTP calls (seconds)
OLLAMA_TIMEOUT_SECONDS=30

# Enable per-session dialog memory (default: false)
# If true, client must send X-Session-ID header for continuity.
ENABLE_DIALOG_MEMORY=false

# Show rewrite-debug page in UI (default: false)
SHOW_REWRITE_DEBUG=false

DATA_RAW_DIR=data/raw
DATA_CLEAN_DIR=data/clean

OLLAMA_CHAT_MODEL=llama3.1:8b
OLLAMA_EMBED_MODEL=nomic-embed-text
UI_PORT=8501
