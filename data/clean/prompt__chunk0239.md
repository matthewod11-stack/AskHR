---
source_path: prompt.md
pages: n/a-n/a
chunk_id: c36e9f0ec31b81366e3c78d220e0b282ca9d1fe4
title: prompt
---
# Self-consistency

While large language models have shown impressive success in various NLP tasks, their

ability to reason is o(cid:454)en seen as a limitation that cannot be overcome solely by increasing

model size. As we learned in the previous Chain of Thought prompting section, the model can

be prompted to generate reasoning steps like a human solving a problem. However CoT uses a simple ‘greedy decoding’ strategy, limiting its e(cid:441)ectiveness. Self-consistency11 combines sampling and majority voting to generate diverse reasoning paths and select the most

consistent answer. It improves the accuracy and coherence of responses generated by LLMs.

Self-consistency gives a pseudo-probability likelihood of an answer being correct, but

obviously has high costs.

It follows the following steps:

- 1. Generating diverse reasoning paths: The LLM is provided with the same prompt multiple

times. A high temperature se(cid:459)ing encourages the model to generate di(cid:441)erent reasoning
