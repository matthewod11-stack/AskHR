---
source_path: industrial_organizational_psychology_an_applied_approach.md
pages: n/a-n/a
chunk_id: 72fafcda0a2a1832f40cfaa19fe1588695938c35
title: industrial_organizational_psychology_an_applied_approach
---
# Problems with Unstructured Interviews Why does the unstructured interview seem not to predict future employee performance? Researchers have investigated this question for several years and have identified eight factors that contribute to the poor reliability and validity of the unstructured interview: poor intuitive ability, lack of job relatedness, primacy effects, contrast effects, negative-information bias, interviewer-interviewee similarity, interviewee appearance, and nonverbal cues. Poor Intuitive Ability Interviewers often base their hiring decisions on “gut reactions,” or intuition. However, people are not good at using intuition to predict behavior: research indi- cates that human intuition and judgment are inaccurate predictors of a variety of factors ranging from future employee success to the detection of deception (Aamodt, ). And contrary to what many HR professionals think, there are no individual differences in interviewers’ ability to predict future performance (Pulakos, Schmitt, Whitney, & Smith, ). That is, research does not support the idea that some interviewers are able to predict behavior, whereas others are not. Divorce rates provide an excellent example of this poor predictive ability. Figure 4.8 Commonly asked unstructered employment interview questions Couples involved in romantic relationships spend, on average, two years together before getting married. In spite of this time together, % of all marriages fail—an important reason for which is lack of compatibility. So, if after two years of “inter- viewing” a prospective spouse, we make the wrong choice % of the time, is it logical to assume that after spending only  minutes interviewing an appli- cant we can predict how well she will get along with the varied members of an organization? Lack of Job Relatedness Research by Bolles () has identified the most common questions asked by interviewers. As you can see in Figure ., these questions are not related to any particular job. Furthermore, the proper answers to these questions have not been empirically determined. Research has shown which answers personnel manag- ers prefer (Bolles, ), but preference for an answer does not imply that it will actually predict future performance on the job. As discussed earlier in this and preceding chapters, information that is used to select employees must be job related if it is to have any chance of predicting future employee performance. In addition to not being job related, many questions asked by interviewers are illegal (e.g., “Are you married?” or “Do you have any health problems?”). Interestingly, most interviewers who ask illegal questions know that they are illegal (Dew & Steiner, ). Primacy Eff ects The research on the importance of primacy effects or “first impressions” in the interview is mixed. Some research indicates that information presented prior to the interview (Dougherty, Turban, & Callender, ) or early in the inter- view carries more weight than does information presented later in the interview (Farr, ). Furthermore, it has been suggested that interviewers decide about a candidate within the first few minutes of an interview (Dessler, ; Otting, ). In fact, of a group of personnel professionals, % said they can make a decision within the first five minutes of an interview (Buckley & Eder, ) and two studies (Giluk, Stewart, & Shaffer; ; Stewart, Dustin, Shaffer, & Giluk, ) found a high correlation between interviewer ratings made after a few minutes of rapport building and the final interview rating. However, more recent research (Raymark, Keith, Odle-Dusseau, Giumetti, Brown, & Van Iddekinge, ) found that only % of interviewers made up their mind in the first minute and only % within the first five minutes. Thus, most interviewers take at least five minutes to make their decisions. As one would imagine, the time taken by interviewers to make a decision was influenced by - 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Why should I hire you? What do you see yourself doing five years from now? What do you consider your greatest strengths and weaknesses? How would you describe yourself? What college subjects did you like best? Least? What do you know about our company? Why did you decide to seek a position with the company? Why did you leave your last job? What do you want to earn five years from now? What do you really want to do in life? employee selection: recruiting and interviewing 137 138 chapter  several factors such as the degree to which the interview is structured, the behav- ior of the interviewee, and the interview dimensions being tapped. To reduce potential primacy effects, interviewers are advised to make repeated judgments throughout the interview rather than one overall judgment at the end of the interview. That is, the interviewer might rate the applicant’s response after each question or series of questions rather than waiting until the end of the interview to make a single rating or judgment. Contrast Eff ects With the contrast effect, the interview performance of one applicant may affect the interview score given to the next applicant (Oduwole, Morgan, & Bernardo, ; Wexley, Sanders, & Yukl, ). If a terrible applicant precedes an average applicant, the interview score for the average applicant will be higher than if no applicant or a very qualified applicant preceded her. In other words, an applicant’s performance is judged in relation to the performance of previous interviewees. Thus, it may be advantageous to be interviewed immediately after someone who has done poorly. Research by Wexley, Yukl, Kovacs, and Sanders () found that interviewers who were trained to be aware of the occurrence of contrast effects were able to reduce them. Other researchers (Landy & Bates, ), however, have questioned whether the contrast effect actually plays a significant role in the interview process. Negative-Information Bias Negative information apparently weighs more heavily than positive information (Bocketti, Hamilton, & Maser, ; Rowe, ). Negative-information bias seems to occur only when interviewers aren’t aware of job requirements (Langdale & Weitz, ). It seems to support the observation that most job applicants are afraid of being honest in interviews for fear that one negative response will cost them their job opportunities. This lack of honesty may be especially evident in the interview, where the face-to-face nature of the process increases the odds that an applicant would respond in such a way as to look better to the interviewer. In a study conducted to increase the honesty of applicants during the interview process, Martin and Nagao () had applicants interview for a job in one of four conditions. In the first, applicants read written interview questions and then wrote their responses to the questions. In the second condition, applicants were “ interviewed” by a computer. In the third condition, applicants were interviewed face-to-face by an interviewer who behaved warmly; and in the fourth condition, applicants were interviewed by an interviewer who seemed cold. As expected, Martin and Nagao found that applicants were more honest in reporting their GPAs and their SAT scores under the nonsocial conditions that involved paper-and-pencil and computer interviewing. Thus, one might increase the accuracy of informa- tion obtained in the interview by reducing social pressure and using written or computerized interviews. Interviewer-Interviewee Similarity In general, research suggests that an interviewee will receive a higher score (Howard & Ferris, ) if he or she is similar to the interviewer in terms of personality (Foster, ), attitude (Frank & Hackman, ), gender (Foster, Dingman, Muscolino, & Jankowski, ), or race (McFarland, Sacco, Ryan, & Kriska, ; Prewett-Livingston et al., ). However, a study by Sacco, Scheu, Ryan, and Schmitt () found that the method used to analyze interview data is a factor in whether similarity matters. Sacco et al. found that when using a traditional approach (d scores) to analyze their findings, interviewers gave higher ratings to same-race interviewees. When a more sophisticated method was used (hierarchical linear models), neither racial nor sex similarity affected interview scores. Thus, further research is needed to accurately determine the importance of similarity in interview decisions. Interviewee Appearance Meta-analyses (Barrick, Shaffer, & DeGrassi, ; Hosada, Stone-Romero, & Coats, ; Steggert, Chrisman, & Haap, ) indicate that, in general, physically attractive applicants have an advantage in interviews over less attractive applicants and applicants who dress professionally receive higher interview scores than do more poorly dressed applicants. This attractiveness bias occurred for men and women and for traditionally masculine and feminine job types. The appearance bias extends to weight, as research (Kutcher & Bragger, ; Pingitore, Dugoni, Tindale, & Spring, ) indicates that obese applicants receive lower interview scores than their leaner counterparts. Interviewee appearance, it seems, is a potent hiring factor (Posthuma, Morgeson, & Campion, ). Nonverbal Cues A meta-analysis by Barrick et al. () found that the use of appropri- ate nonverbal communication is highly correlated with interview scores. Appropriate nonverbal cues include such things as smiling and making appropriate eye contact (Levine & Feldman, ). Howard and Ferris () found a significant relationship between use of appropriate nonverbal behaviors and interviewer perceptions of interviewee competence. Not sur- prisingly, meta-analysis results indicate that structured interviews are not as affected by nonverbal cues as are
