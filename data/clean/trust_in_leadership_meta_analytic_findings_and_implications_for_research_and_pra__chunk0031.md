# samples

Both authors coded the statistics (sample size, effect size, reliability, etc.) and moderator variables for each study included in the analysis. During the first round of coding, interrater agreement on the referent variable was .93 (kappa (cid:1) .85) and on the definition variable was .72 (kappa (cid:1) .41). The decision rules for “definition” were revised to be more precise, and the studies were subsequently recoded. During the second round of coding of the definition variable, agreement was .97 (kappa (cid:1) .95). Existing cases of disagreement were resolved by discussion.