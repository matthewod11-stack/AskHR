## First, from a design perspective, seemingly innocuous choices of how

we architect AI-powered tools can have a substantial impact on their

eﬀects. Take the somewhat mundane example of spell check. Most spell

checkers don’t automatically ﬁx words as you type without feedback.

Instead, they provide cues that indicate a potential misspelling and

oﬀer an opportunity to not only correct what’s written, but to visualize

the proper spelling. This small choice shifts spell check from being a

kind of a steroid to more of a coach. It improves your ﬁnal product while

also helping you learn from your mistake (or typo).

By thinking intentionally about how we design AI tools, we can

minimize or avoid harmful long-term eﬀects. For instance, our own

recent experiments show that simple conﬁdence-based highlighting,

similar to what’s done in spelling and grammar check, can help people

spot and correct fabrications or “hallucinations” produced by LLM-

based search tools. The idea is that if we can show people which bits

of information in an LLM-generated response might be less reliable, we

can help them spot and ﬁx potential errors. This would still oﬀer the

chance for productivity gains while maintaining the necessary cues for

cognitive awareness of where LLM-based responses can go wrong. With

thoughtful design we can develop helpful co-pilots that augment, rather

than replace, people in getting work done.