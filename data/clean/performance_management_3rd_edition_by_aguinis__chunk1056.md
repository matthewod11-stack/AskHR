---
source_path: performance_management_3rd_edition_by_aguinis.md
pages: n/a-n/a
chunk_id: dbecdf8b0d14fb161595f18cc5b5f827f3b9b93d
title: performance_management_3rd_edition_by_aguinis
---
# Part II • System Implementation

Finally, the form shows the scores obtained for the competencies and the key results in each of the two halves of the review period. To obtain the overall performance score, we simply take an average of these four numbers: (3.7 (cid:2) 2.7 (cid:2) 1.6 (cid:2) 3.4)/4 (cid:4) 2.85. This puts Carmello in the 2.6–3.5 range, which represents a qualification of “above average.” Now, suppose that we do not follow a mechanical procedure to compute overall performance score, and instead we use a judgmental method. That is, suppose raters have no information on weights. How would James LeBrown, Carmello’s supervisor, compute the overall performance score? One possibility is that he might give equal weights to all competencies and would therefore consider that Follow-Through/Dependability is as important as Decision Making/Creative Problem Solving. This would lead to different scores compared to using weights of .7 and .3. As an alternative, the supervisor may have his own ideas about what performance dimensions should be given more weight and decide to ignore how the work is done (i.e., behaviors) and instead assign an overall score based primarily on the key results (i.e., sales and margin balance).

The use of weights allows the supervisor to come to an objective and clear overall performance score for each employee. As this example illustrates, the use of clearly specified weights allows the supervisor to come to a verifiable score for each employee. Thus, the supervisor and the employees can be sure that the overall performance rating is reflective of the employee’s performance in each category.

Which strategy is the best: judgmental or mechanical? In most cases, the mechanical method is superior to the judgmental method.5 A supervisor is more likely to introduce his or her own biases in computing the overall performance score when no clear rules exist regarding the relative importance of the various performance dimensions and there is no direction on how to combine the various performance dimensions in calcu- lating the overall score.6 As far as the computation of overall scores goes, the mechani- cal method is superior to the judgmental method.

Finally, you will notice that the form included in Figure 6.3 includes sections labeled “comments.” These open-ended sections are common in most appraisal forms. However, this information is typically not used effectively.7 Likely, there are two chief reasons that this is the case. First, it is not easy to systematically categorize and analyze such com- ments. Second, the quality, length, and content of these comments may be more a function of the culture of the organization and the writing skills of the person filling out the form than actual KSAs of the employee being rated. Regarding the first challenge, the increas- ing sophistication of computer-aided text analysis (CATA) software that allows for an analysis of text (as opposed to numbers) may allow for more and better use of such infor- mation. For example, the software package DICTION 5.0 allows for the analysis of text by first creating categories of terms or phrases and then counting the relative frequency of each.8 So, an organization may wish to classify the comments in terms of, for example, task and contextual performance. Then, a “dictionary” of terms and phrases related to each of these performance dimensions is created and the software automatically counts the number of times that such types of behaviors are mentioned in the comments. The second challenge is more difficult to overcome because if raters are not given any training or general instructions on what two write, comments may range from none at all to very detailed descriptions of what employees have done (i.e., past orientation) and very de- tailed descriptions of what employees should do (i.e., future orientation). Thus, to over- come this second challenge, it is important to first establish the goals of the information that raters are asked to include in these open-ended sections and then offer raters training
