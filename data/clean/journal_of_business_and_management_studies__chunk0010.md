---
source_path: journal_of_business_and_management_studies.md
pages: n/a-n/a
chunk_id: e63eefcfe871217e5a1c6eb5fc5452f3e570c4df
title: journal_of_business_and_management_studies
---
# JBMS 6(3): 47-59

methods and validating feature importance through multi-criteria models could have potentially led to even higher levels of accuracy.

- 3. Methodology In this research paper, the investigator uses Jupyter Notebook, an interactive platform for Python users, to design machine learning algorithms. According to Hasan et al (2024), Python is an open-source program prevalently utilized for data science and machine learning tasks. Besides, R programming was also used, which is also an open-source language for developing machine learning algorithms. R-programming affords various graphical and statistical approaches for evaluating data and crafting predictive analytics resolutions. Both Python and R-system were considered appropriate programming languages for the objective of this study, as they provide robust libraries and functionality for employing machine learning techniques and constructing predictive models from data. 3.1 Dataset The dataset utilized in this research was attained from the IBM Human Resource workforce attrition survey dataset. Initially, the dataset comprised 35 features or variables. Nevertheless, 14 of these attributes were pinpointed as redundant and eliminated via data cleaning. This culminated in a final dataset with 21 attributes. Table 1 highlights and portrays these 21 attributes, entailing their distinguished data types as either numeric or non-numeric categorical variables (Pro-AI-Rokibul, 2024). Ultimately, these attributes capture distinct components of employees' job satisfaction, demographic characteristics, and work environment, to assist in evaluating and predicting the likelihood of attrition.

3.2 Pre-Processing Pre-processing entailed data reduction and cleaning was performed, comprising tasks such as the transformation of feature type from numerical to nominal. Based on the pre-processing, four (4) features were pinpointed and subsequently eliminated, resulting in a remaining set of 21 attributes (Pro-AI-Rokibul, 2024). After the production of the interquartile filter, outliers were detected and eliminated in the dataset.

S/No 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 17 18 19 20 21

Attribute Age bracket Daily Rate Department Business Travel Education Gender Distance from home Job involvement Hourly Rate Job Satisfaction Job level Job role Monthly rate Monthly income Number of organizations worked Performance rating Total Working Years Years at the Organization Years at the Present Role Work-Life Balance

Data Type Numeric type Numeric Categorical Categorical Categorical Categorical Numeric Categorical Numeric Categorical Categorical Categorical Numeric Numeric Numeric Categorical Numeric Numeric Numeric Categorical

3.3 Feature Engineering Selection Feature selection in this research entailed the careful selection of relevant features while discarding redundant and irrelevant information from the dataset. The objective was to diminish the dimensionality of the dataset, therefore enhancing accuracy, combating overfitting, minimizing training time, and pinpointing the most subjective and predictive domains for the evaluation (Pro-AI-Rokibul, 2024). Several feature selection techniques, such as Symmetrical Uncertainty Attributes, Gain Ratio Attributes, and Correlation Attributes, were adopted to choose the top twenty-one features out of the total of 30 features.

Page | 49
