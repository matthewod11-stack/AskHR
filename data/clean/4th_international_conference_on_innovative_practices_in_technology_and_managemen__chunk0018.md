# kernel

functions,

KNN offers a versatile and user-friendly method for predicting staff attrition. Instances are categorized by this approach according to the feature space's k-nearest neighbors' majority class. KNN is useful in identifying minute elements that contribute to employee turnover because it may capture

2

Authorized licensed use limited to: Visvesvaraya Technological University Belagavi. Downloaded on July 18,2024 at 09:29:23 UTC from IEEE Xplore. Restrictions apply.

local patterns and dependencies in the data related to attrition. Model development and interpretation can be completed quickly thanks to its simplicity and convenience of use. KNN works especially well in situations with complex and non- linear decision boundaries [18]. For best results, however, factors like choosing a suitable number for k and dealing with unbalanced datasets are essential. Even while KNN may not be as computationally efficient as some other algorithms, its versatility in handling a variety of datasets and capacity to identify patterns in the instantaneous framework of attrition events by making it a valuable tool in the predictive analytics toolbox for employee attrition. F. Extreme Gradient Boosting (XGBoost)

simplicity, logistic regression offers insightful information about the significance of features. It turns out that Extreme Gradient Boosting is a potent ensemble technique with excellent prediction accuracy. By enabling to proactively recognize and manage attrition risks, these models help to design focused retention strategies. It is imperative to acknowledge that the selection of the best appropriate model is contingent upon the distinct attributes of the dataset and the particular study situation. As the area develops, more research can focus on improving these models and investigating cutting-edge strategies to increase the efficacy of employee attrition prediction in organizational contexts.