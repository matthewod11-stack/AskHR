---
source_path: agents_companion.md
pages: n/a-n/a
chunk_id: 747ccac1342a497032e9578d0ceb16909cdfcfa4
title: agents_companion
---
# More about Agent Evaluation

In this section we cover agent evaluation from the practical perspective. But this is just the tip

of the iceberg. Agent evaluation presents many challenges. Evaluation data for your agents

may be difficult to find. While synthetic data or LLMs as judges can be used, evaluations

may still be incomplete. Also, LLM-as-a-Judge metrics, for example, may prioritize final

outcomes over the agent's reasoning and intermediate actions, potentially missing key

insights. Additionally, as evaluations for agent systems have a history in conversational and

workflow systems, there is so much to explore on how to inherit methods and metrics to

evaluate agent's capabilities, such as the ability to improve task performance over multiple

interactions. Evaluations for multi-modal generations pose additional complexities; images,

audio, and video evaluations require their own evaluation methods and metrics. Finally, real-

world environments pose further challenges, as they are dynamic and unpredictable, making

it difficult to evaluate agents in controlled settings.

Looking ahead, to solve these open challenges, the field of agent evaluation is evolving

rapidly. Key trends include a shift towards process-based evaluation, prioritizing the
