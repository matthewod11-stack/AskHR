# Behaviorally Anchored Rating Scales

To reduce the rating problems associated with graphic rating scales, Smith and Kendall () developed behaviorally anchored rating scales (BARS). As shown in Figure ., BARS use critical incidents (samples of behavior) to formally provide meaning to the numbers on a rating scale. Although BARS are time- consuming to construct, the process is not overly complicated.

Creating BARS Generation of Job Dimensions In the first step in BARS construction, the number and nature of job-related dimensions are determined. If a job analysis has already been conducted, the dimensions can be obtained from the job analysis report. If for some reason a job analysis has not been conducted, a panel of some  job experts—the employees—is formed. This panel determines the important dimensions on which an employee’s performance should be evaluated. If  to  employees are not available, several supervisors can meet and develop the job dimensions as a group (Shapira & Shirom, ). Usually,  to  dimensions are generated (Schwab et al., ).

Generation of Critical Incidents Once the relevant job dimensions have been identified, employees are asked to generate examples of good, average, and bad behavior that they have seen for each dimension. Thus, if five dimensions have been identified, each employee is asked to generate  critical incidents—a good, an average, and a bad incident— for each of the five dimensions. If the organization is fairly small, employees may need to generate more than one example of the three types of behavior for each dimension.

Sorting Incidents To make sure that the incidents written for each job dimension are actually examples of behavior for that dimension, three job experts independently sort the incidents into each of the job dimensions. The dimension into which each incident has been sorted by each of the three sorters then is examined. If at least two sorters placed an incident in the same dimension, the incident becomes part of that dimension. But if each sorter has placed the incident in a different category, the incident is considered to be ambiguous and thus is discarded.

Three sorters achieve results similar to those for  sorters (Chapter ). Many developers of BARS, however, use as many sorters as possible so that employees have a part in developing the scales. If many employees are involved, a % level of sorter agreement should be used to determine whether an incident is part of a dimension.

evaluating employee performance

281

Rating Incidents Another group of job experts is given the incidents and asked to rate each one on a scale that can have from five to nine points as to the level of job performance that it represents (Bernardin, LaShells, Smith, & Alveres, ). The ratings from each rater for all of the incidents are then used to determine the mean rating and standard deviation for each incident (typically by computer).

Choosing Incidents The goal of this step is to find one incident to represent each of the points on the scale for each dimension. To do so, the incidents whose mean ratings come closest to each of the scale points and whose standard deviations are small are kept (Maiorca, ). This procedure usually results in the retention of less than % of the incidents (Green, Sauser, Fagg, & Champion, ).

Creating the Scale The incidents chosen in the previous step are then placed on a vertical scale such as that shown in Figure .. Because the mean for each incident is unlikely to fall exactly on one of the scale points, they are often placed between the points, thus serving as anchors for future raters.