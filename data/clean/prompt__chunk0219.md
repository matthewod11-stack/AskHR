# chain of thought.

CoT has a lot of advantages. First of all, it’s low-e(cid:441)o(cid:457) while being very e(cid:441)ective and works

well with o(cid:441)-the-shelf LLMs (so no need to (cid:450)netune). You also get interpretability with CoT

prompting, as you can learn from the LLM’s responses and see the reasoning steps that were

followed. If there’s a malfunction, you will be able to identify it. Chain of thought appears

to improve robustness when moving between di(cid:441)erent LLM versions. Which means the

pe(cid:455)ormance of your prompt should dri(cid:454) less between di(cid:441)erent LLMs than if your prompt

does not use reasoning chains. Of course there are also disadvantages, but they are