---
source_path: industrial_organizational_psychology_an_applied_approach.md
pages: n/a-n/a
chunk_id: e46b2175c0a13c463db0feb9bb08fc7581990017
title: industrial_organizational_psychology_an_applied_approach
---
# Halo Catherine Willows Cooperation 1 2 3 4 5 1 2 3 4 5 Knowledge 1 2 3 4 5 Leadership Gil Grissom Cooperation 1 2 3 4 5 1 2 3 4 5 Knowledge 1 2 3 4 5 Leadership Catherine Willows Cooperation 1 2 3 4 5 1 2 3 4 5 Knowledge 1 2 3 4 5 Leadership Nick Stokes Cooperation 1 2 3 4 5 1 2 3 4 5 Knowledge 1 2 3 4 5 Leadership Warrick Brown Cooperation 1 2 3 4 5 1 2 3 4 5 Knowledge 1 2 3 4 5 Leadership Nick Stokes Cooperation 1 2 3 4 5 1 2 3 4 5 Knowledge 1 2 3 4 5 Leadership has been evaluated immediately after Carr. Her performance has been contrasted to Carr’s performance rather than to some objective standard. Such contrast errors can also occur between separate performance evalu- ations of the same person. That is, the ratings received on one performance appraisal will affect the ratings made on an appraisal six months later. For example, an employee’s performance during the first six months of the year is “excellent,” and she receives outstanding performance ratings. For some reason, the employee’s actual behavior in the next six months is only “good.” What type of performance ratings will she receive? Based on the results of a study by Murphy, Gannett, Herr, and Chen (), the answer probably is that her ratings will be less than “good.” In contrast to her initial excellent performance, the employee’s subsequent performance (which may indeed have been “good”) appeared to be lower than it actually was. Contrast effects occur only when the person making the evaluation actually sees the employee perform (Smither, Reilly, & Buda, ) and rates the employee (Summer & Knight, ) during both rating periods. If a new supervisor reads that an employee’s previous evaluations were excellent but she observes poor performance by the employee, she will proba- bly continue to give excellent ratings—even though the employee’s performance deteriorated. Smither and his colleagues call this rating error assimilation. To get a better feel for rating errors, complete Exercise . in your workbook. Low Reliability across Raters As shown back in Table ., two people rating the same employee seldom agree with each other (Conway & Huffcut, ; Viswesvaran, Ones, & Schmidt, ). There are three major reasons for this lack of reliability. First, raters often commit the rating errors previously discussed (e.g., halo, leniency). Thus, if one rater engages in halo error and another in contrast error, it is not surprising that their ratings of the same employee are different. Second, raters often have very different standards and ideas about the ideal employee. For example, I recently conducted a performance appraisal workshop for a police department. After viewing a video clip of an officer handling a distur- bance call, one sergeant rated the officer’s performance as excellent and another rated the officer’s performance as being terrible. When asked about their differ- ent ratings, one sergeant indicated that he thought officers should be aggressive and take command of a situation, whereas the other sergeant thought officers should be more citizen oriented. Thus, the same employee behavior elicited two very different ratings because each sergeant had a different “prototype” of the ideal cop. Third, as mentioned earlier in the chapter, two different raters may actually see very different behaviors by the same employee. For example, a desk sergeant may see more administrative and paperwork behaviors, whereas a field sergeant may see more law enforcement behaviors. Thus, different ratings by the two sergeants may simply reflect the fact that each has observed the officer perform in very different situations. As mentioned earlier, one way to reduce the number of rating errors and increase reliability is to train the people who will be making the performance evaluations (Hauenstein, ). Sampling Problems Recency Effect. Performance appraisals are typically conducted once or twice a year. The evaluation is designed to cover all of the behaviors that have taken place during the previous  months to a year. Research has demonstrated, however, that recent behaviors are given more weight in the performance evaluation than behaviors that occurred during the first few months of the evaluation period. Such an effect penalizes workers who performed well during most of the period but tailed off toward the end, and it rewards workers who saved their best work until just before the evaluation. In baseball, the Los Angeles Dodgers had several years where they lost many games early in the season, which eliminated them from pennant contention. But several players played well and produced great statistics during the final month of the season; the press called this period the “salary drive,” as opposed to the “pen- nant drive.” This suggests that the players may have been aware of the recency effect. They hoped that high performance before contracts were renewed would bring better evaluations and thus higher salaries for the next year. It seems that students are well aware of the recency effect when they argue that the high score on their final exam should carry more weight than the lower scores on previous exams! Infrequent Observation. As shown back in Figure ., another problem that affects performance appraisals is that many managers or supervisors do not have the opportunity to observe a representative sample of employee behavior. Infrequent observation occurs for two reasons. First, managers are often so busy with their own work that they have no time to “walk the floor” and observe their employees’ behavior. Instead, they make inferences based on completed work or employee personality traits (Feldman, ). A good example involves a teacher who completes a reference form for a student. Reference forms commonly ask about characteristics such as the applicant’s ability to cooperate or to get along with others. The teacher must base her evaluation on the term papers that she has evaluating employee performance 267 268 chapter  seen and the student’s test grades. Rarely does she have the opportunity to watch the student “get along with” or “cooperate with others.” Instead, because a group project was turned in on time and received an excellent grade, she surmises that the student must have cooperated and gotten along well with other group members. Employees often act differently around a supervisor than around other work- ers, which is the second reason managers usually do not make accurate obser- vations. When the supervisor is absent, an employee may break rules, show up late, or work slowly. But when the boss is around, the employee becomes a model worker. In the eyes of the supervisor, the employee is doing an excellent job; the other workers, however, know better. As discussed earlier in the chapter, this problem can be alleviated somewhat by having several raters evaluate the employee. Other raters can be other super- visors, fellow workers (peer ratings), and even customers. A meta-analysis by Conway and Huffcutt () indicated that supervisor ratings on the average correlate . with peer ratings. Thus, even though the two groups somewhat agree, the agreement is certainly not perfect. Unfortunately, ratings from these sources are often subject to more errors than the uninformed ratings made by a supervisor. For example, customers may complain about a worker even though she is following policy, and a worker may provide low evaluations of her coworkers so that she will receive a higher raise. Even with these problems, multiple raters remain a good idea. Cognitive Processing of Observed Behavior Observation of Behavior. As shown in Figure ., just because an employee’s behav- ior is observed does not guarantee that it will be properly remembered or recalled during the performance appraisal review. In fact, research indicates that raters recall those behaviors that are consistent with their general impression of an employee (Cooper, a; Feldman, ; Martell, Guzzo, & Willis, ), and the greater the time interval between the actual behavior and the perfor- mance rating, the greater the probability that rating errors will occur (Murphy, Martin, & Garcia, ; Nathan & Lord, ). Furthermore, raters who are familiar with the job being evaluated recall more judgments about performance but fewer behaviors than do raters who are unfamiliar with the job (Harriman & Kovach, ; Hauenstein, ). The decrease in memory accuracy over time can be reduced if several raters, rather than one, are used to evaluate perfor- mance (Martell & Borg, ). But even though memory-based ratings lead to more distortion, in many circumstances they are more accurate than ratings made immediately after the behaviors occur (Murphy & Balzer, ). The reason for these increases in halo and accuracy is not yet clear. Supervisors perhaps realize that it will be a long interval between observation of employee behavior and the formal evaluation of that behavior and that they will not be able (without great effort or the use of log books) to remember specific behaviors. Thus, they form an overall impression of the employee and an overall impression of
