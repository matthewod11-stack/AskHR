---
source_path: 13.md
pages: n/a-n/a
chunk_id: 628c9d4e54d0a47400b18580d0f55b36bff4772d
title: '13'
---
## The Past, Present, and Future of Dynamic Performance Research

dynamic criteria (as speciﬁed by the second deﬁnition) was relatively rare. Other researchers took an opposing view, arguing that the same evidence reviewed in Barrett et al. (1985) was not as dismissive of a dynamic criterion as Barrett et al. suggest (Austin et al., 1989). A similar debate emerged soon thereafter. A paper by Henry and Hulin (1987) argued that ‘‘instability and change in nearly all areas of human performance, skills, and measures of general ability are more to be expected than is stability’’ (p. 461) and therefore the long-term predictability of performance is questionable. This paper was criticized by Ackerman (1989), who argued that while job performance ratings may follow a simplex patter, ‘‘ability measures can maintain levels of predictive validity over time and, when chosen properly, may actually increase’’ (Ackerman, 1989, p. 364), followed by a rejoinder by Henry and Hulin (1989) countering some of the criticisms. The point here is not speciﬁcally to weigh in on these debates, but their review shows that there are divergent opinions on the matter, and the evidence had not yielded deﬁnitive conclusions for the ﬁeld.

the most comprehensive examinations of performance predictors over time, Keil and Cortina (2001) examined the validity of cognitive ability, perceptual speed ability, and psychomotor ability to predict job performance. They found that the validities deteriorate with time. This deterioration occurred for all three predictors, and for both consistent and inconsistent tasks. Although they argued that this deteriora- tion is pervasive, there are still examples from other research of selection devices maintaining their predictability over time.
