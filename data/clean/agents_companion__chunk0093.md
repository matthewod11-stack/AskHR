---
source_path: agents_companion.md
pages: n/a-n/a
chunk_id: 2cc5413e235690907cbcb19a0089b012d6a276fe
title: agents_companion
---
# Human-in-the-Loop Evaluation

The fields of agent development and agent evaluation are rapidly evolving. Evaluating

AI agents presents significant challenges, including defining clear objectives, designing

realistic environments, managing stochastic behavior, and ensuring fairness and bias

mitigation, particularly in socially impactful applications. Therefore, it's crucial to incorporate

a human-in-the-loop approach alongside the automated evaluations discussed previously

(which involve predefined metrics and autoraters). Human-in-the-loop is valuable for tasks

requiring subjective judgment or creative problem-solving, it can also serve to calibrate and

double-check if your automated evaluation approaches actually work and align with your

preferences. Key benefits include:

- Subjectivity: Humans can evaluate qualities that are difficult to quantify, such as
