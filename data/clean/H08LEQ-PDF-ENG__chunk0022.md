---
source_path: H08LEQ-PDF-ENG.md
pages: n/a-n/a
chunk_id: 66adc56e696be2d70403272300fc4f0e21e8d5a5
title: H08LEQ-PDF-ENG
---
# overall content quality on the platform.

Synthesizing multiple types of data

The digital era focused on bits and bytes; the AI revolution is “multi-

modal.” That is, AI systems can now process information from diﬀering

modalities, including text, images, audio, video, and other sensory

input. Of course we humans have always been multi-modal, processing

and synthesizing all kinds of information in the real world we inhabit.

Now, with multi-modal AI, we have a technology that mimics our ability

to interpret and integrate a broad spectrum of information and that can

communicate and interact with us wherever we are, engaging with us in

a way that ﬁts our preferences, surroundings, and intentions. No longer
