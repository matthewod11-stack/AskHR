---
source_path: reinventing_performance.md
pages: n/a-n/a
chunk_id: 63a7f567ee44b9a1c45ff7bc6bff7fc0d8c24468
title: reinventing_performance
---
# HBR.ORG

Idea in Brief THE PROBLEM Not just employees but their managers and even HR departments are by now questioning the conventional wisdom of performance management, including its common reliance on cascading objectives, backward-looking assessments, once-a-year rankings and reviews, and 360-degree-feedback tools.

THE GOAL Some companies have ditched the rankings and even annual reviews, but they haven’t found better solutions. Deloitte resolved to design a system that would fairly recognize varying performance, have a clear view into performance anytime, and boost performance in the future.

THE SOLUTION Deloitte’s new approach separates compensation decisions from day-to-day performance management, produces better insight through quarterly or per-project “performance snapshots,” and relies on weekly check-ins with managers to keep performance on course.

fair. We realize, however, that it’s no longer the best design for Deloitte’s emerging needs: Once-a-year goals are too “batched” for a real-time world, and conversations about year-end ratings are generally less valuable than conversations conducted in the moment about actual performance.

But the need for change didn’t crystallize until we decided to count things. Specifically, we tallied the number of hours the organization was spending on performance management—and found that com- pleting the forms, holding the meetings, and creat- ing the ratings consumed close to 2 million hours a year. As we studied how those hours were spent, we realized that many of them were eaten up by leaders’ discussions behind closed doors about the outcomes of the process. We wondered if we could somehow shift our investment of time from talking to our- selves about ratings to talking to our people about their performance and careers—from a focus on the past to a focus on the future.

We tallied the number of hours the organization was spending on performance management and found that creating the ratings consumed close to 2 million hours a year.

The Science of Ratings Our next discovery was that assessing someone’s skills produces inconsistent data. Objective as I may try to be in evaluating you on, say, strategic think- ing, it turns out that how much strategic thinking I do, or how valuable I think strategic thinking is, or how tough a rater I am significantly affects my as- sessment of your strategic thinking.

How significantly? The most comprehensive research on what ratings actually measure was conducted by Michael Mount, Steven Scullen, and Maynard Goff and published in the Journal of Applied Psychology in 2000. Their study—in which 4,492 managers were rated on certain per- formance dimensions by two bosses, two peers, and two subordinates—revealed that 62% of the variance in the ratings could be accounted for by individual raters’ peculiarities of perception. Actual

April 2015 Harvard Business Review 43
