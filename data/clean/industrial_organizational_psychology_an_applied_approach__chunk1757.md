# After months of study and

work, we elected to develop a phased-in behavioral and competency-based program using a simple rating scale of

0 to 3: needs improvement, competent, commendable, and outstanding/ exceptional, respectively. Phase I implementation involved the setting of six county/core competencies with behavioral statements. The employee team, along with the county’s management team, consti- tutional officers, and agency heads, provided input into developing the competencies, which are customer service, compliance with policies and procedures, teamwork, communication skills, departmental/job knowledge, and training/self-development/ continuous improvement. The team spent considerable time on the numeric elements of the system and geared its design on the positive side, with really only one negative dimension,

needs improvement. They chose a very simple system that could not be connected with an “average” or a school grading system. To date, it has followed a fairly predictable bell curve with results. Linking pay to it has been considered but has not been implemented as yet. I facilitated introductory

training sessions on the planned program to all evaluators and employees. These sessions included training on conducting performance appraisals, eliminating rater bias, how to write position competencies and behaviors (for Phase II), and documenting performance issues. All supervisors also received 6 hours of basic supervisory skills training on documentation, coaching, time management, and delegation. Phase II involved directors,

dimensions rather than rating error. Thus a teacher who is rated highly in class- room teaching, ability to work with students, knowledge, and fairness of grading actually may excel in those things. At this time, the best explanation for the con- sistency across rating dimensions is that some of the consistency is due to actual performance and some to halo and other rating errors (Viswesvaran et al., ). Halo errors may or may not be a serious problem (Balzer & Sulsky, ), but they can be reduced by having supervisors rate each trait at separate times. That is, the supervisor might rate the employee on attendance one day and then on dependability the next. Of course, in reality, such a practice is seldom possible. Examples of halo, leniency, central tendency, and strictness errors are shown in Figure ..

Proximity Errors Proximity errors occur when a rating made on one dimension affects the rat- ing made on the dimension that immediately follows it on the rating scale. For example, a supervisor gives an employee a rating of  on the first dimension. Because the second dimension is physically located on the rating form next to the

agency heads, and constitutional officers writing position competencies specific to each of their positions. They vary in number; the smaller the number, the larger the weight they carry, since position competencies represent one-half of the total score. Two positions classified the same but crossing departmental lines may have different position competencies based on the particulars in each department/agency.

As part of the original development of the program, plans were included for a career-development component. This has begun to take shape as small groups of employees in career families are planning career paths. These are reviewed for consistency across the board, both internally within

departments and agencies and externally across departmental lines within the county. Since local governments do not always have the opportunity for employees to progress upward through the pay system, “lateral” paths are also being developed, whereby individuals may progress within the same pay range. This allows for professional development and growth throughout the county, thereby encouraging retention.

I have found that a dynamic performance management system is crucial to our workplace. It has to fit the culture of our organization and the expectations of our leadership. It is primarily a communications tool through which feedback and opportunity are intertwined. Without the benchmark of

performance appraisal, the employee is left adrift missing the benefit of knowing where he/she stands. Its absence can be a breeding ground for assumptions and often disappointment. I believe that the basics of a good performance appraisal system can be summarized as follows:

- 1. The fundamental tenets support the mission or goals of the organization; 2. It is consistently applied. It is supported by the 3. leaders of the organization. It is manageable and simple to understand. It provides information to both the employee and the employer. 5.

Although the mechanics of the right system can seem difficult to figure out, in the end it’s about people.

The performance appraisal process is often viewed as time- consuming, but it is also time well spent. It is an investment in the employee and the organization. It yields the rewards that come with paying attention as we lead very hectic lives in the workplace. The process presents an opportunity to celebrate accomplishments, along with providing for planning and direction. It allows for open dialogue about the challenges and concerns that can be present in the employment relationship. Finally, I believe that it provides an assurance that the employee’s successful performance is a priority to the organization. After all, it is in the best interest of both the employer and the employee for that to be so

first, there is a tendency to provide the same rating on both the first and second dimensions. The difference between this error and halo error is in the cause of the error and the number of dimensions affected. With halo error, all dimensions are affected by an overall impression of the employee. With proximity error, only the dimensions physically located nearest a particular dimension on the rating scale are affected; the reason for the effect, in fact, is the close physical proximity of the dimension rather than an overall impression.

Contrast Errors The performance rating one person receives can be influenced by the performance of a previously evaluated person (Bravo & Kravitz, ). For example, a bank manager has six employees who are evaluated twice a year—on February  and again on August . The manager makes the evaluations in alphabetical order, starting with Joan Carr and then going to Donna Chan. Joan Carr is the best employee the bank has ever had, and she receives the highest possible rating on each dimension. After evaluating Carr, the manager then evaluates Chan. When compared with Carr, Chan is not nearly as effective an employee. Thus, Chan receives lower ratings than she might normally receive simply because she

evaluating employee performance

265