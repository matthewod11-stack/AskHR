## HBR / Spotlight / Why People Resist Embracing AI

crisis messages to the apps and asked trained clinical experts to

classify the responses. The experts and I determined that 25% of the AI-

generated responses were problematic because they increased the users’

likelihood of harming themselves. Then we asked a separate group of

people to consider how each app had responded to the crises. Most of

them gave the apps low ratings, indicated that they would stop using the

apps, and said the app companies would be liable if the users ended up

hurting themselves.

Therefore, AI systems must balance ﬂexibility against predictability

and safety. To do that they can incorporate user feedback and include

safeguards for handling unexpected input appropriately.