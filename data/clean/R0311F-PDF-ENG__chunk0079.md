## Coming Up Short on Nonfinancial Performance Measurement

Many companies’ strategic plans are more like mission or vision statements than road maps.

uct of this step is that it begins the process of refining vague or ambiguous definitions and of developing consistent measures for the or- ganization as a whole.

It may be, however, that a company lacks the data it needs even to formulate a causal model. If that’s the case, executives might want to focus first on a performance area be- lieved ultimately to advance the company’s strategy and positively affect corporate finan- cial performance (employee satisfaction, say). Next, it might take a small number of actions believed to improve performance within that area (such as more training). The final step would be to precisely and consistently mea- sure the effects of those actions. Did more training actually increase employee satisfac- tion?

One problem we repeatedly encountered in this step was data “fiefdoms.’’ An automobile manufacturer we studied wanted to determine whether its manufacturing defects were gener- ating too many warranty claims, in which case it would need to change its factory inspections. But the marketing people refused to share their findings with the operations people, mak- ing such detective work impossible. Ulti- mately, a senior executive had to step in.

There are many statistical methods for testing the causal model. Most companies have experience using correlation analyses and multiple re- gressions in their market research and quality improvement efforts. A good example of such statistical techniques is an approach used at Sears, which sought to develop a causal model and scorecard focused on three domains: em- ployee relations (“compelling place to work”), customer satisfaction and loyalty (“compel- ling place to shop”), and results for sharehold- ers (“compelling place to invest”). Like many companies, the retailer had already tracked hundreds of suspected drivers of performance within these domains. Because the data on them came from a large cross section of stores, the company was able to use regression analy- sis to identify the handful of activities that ac- tually were driving performance and there- 2 fore belonged in the causal model.

Turn data into information.

In addition to these familiar statistical tools, a slew of other techniques, many developed by marketers, can be used to validate the as- sumed relationships in the causal model. Qual- itative analyses such as focus groups and one-

on-one interviews can test management’s hunches about what’s important to customers, employees, suppliers, investors, and other stakeholders. For instance, a major industrial gas supplier decided that a primary driver of customer retention was customer satisfaction with the supplier’s billing system. Accordingly, the supplier began soliciting bids for a new, im- proved system. However, interviews with indi- vidual customers revealed that the billing pro- cess was not a major issue. Far more important was technical assistance. On the strength of this finding, the supplier dropped its plans for the new billing system and directed its capital instead to hiring new technicians and retrain- ing existing ones.

Causal mod- eling, if used at all, is often used only once. But reassessment of results should be ongoing and regular. A new competitive environment can weaken or neutralize the effectiveness of for- merly key activities, and the company’s strate- gic response can marginalize once important performance areas.

Continually refine the model.

Even in stable environments, ongoing anal- ysis allows companies to continually refine their performance measures and deepen their understanding of the underlying drivers of eco- nomic performance. For example, a company may believe correctly that low employee ab- senteeism is a key driver of financial perfor- mance, but its managers will still need to know whether employees fail to turn up because they are unhappy with their pay, with their working conditions, or for some other reason. At one information technology company in our study, a cross-functional team conducts analyses of integrated operational, accounting, and customer data every quarter and develops hypotheses about the relationships between particular company efforts and outcomes. For example, what types of customers is the com- pany most likely to lose if operational metrics fall below a certain threshold? Does higher customer satisfaction on some attributes (such as assistance in problem solving or flexibility in meeting changing demands) really lead to higher customer profitability? The hypotheses and associated test results are then presented to senior management. In virtually every meeting, these presentations spark new ques- tions about the underlying drivers of value, which are examined again in the next quarter’s data analysis.

harvard business review • november 2003

This document is authorized for use only by Matt O'Donnell (matthew.od11@gmail.com). Copying or posting is an infringement of copyright. Please contact customerservice@harvardbusiness.org or 800-988-0886 for additional copies.

page 7