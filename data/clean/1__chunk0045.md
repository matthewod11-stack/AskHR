---
source_path: 1.md
pages: n/a-n/a
chunk_id: bb3677f84d8ea119783b87132fa65357363dea14
title: '1'
---
## Case Studies: Real-World AI Hiring Challenges and Biases

The following case studies provide concrete examples of AI hiring system s failing to ensure fairness for disabled individuals:

- Case Study 1 - Workday AI Hiring Bias Lawsuit: Workday's AI hiring tool faced allegations of disproportionately filtering out candidates with disabilities (Derek Mobley v. Workday Inc., 2024). The case highlighted a lack of transparency and accountability in AI hiring decisi ons, resulting in increased scrutiny of compliance requirements.

- Case Study 2 - HireVue Video Interview Bias: HireVue’s AI video interviews relied on facial and speech analysis, disadvantaging candidates with autism, speech disorders , or other impairments (Ajunwa, 2021). Due to regulatory and public pressure, HireVue revised its system to reduce its reliance on facial analysis, instead emphasizing structured interviews.

- Case Study 3 - Facebook’s AI Hiring Discrimination: Facebook’s AI-driven job ad targeting algorithm excluded individuals with disabilities by inferring demographic traits from user data (Jan & Dwoskin, 2019). Civil rights complaints forced the company to revise its ad targeting system to ensure compliance with anti-discrimination laws.

- Case Study 4 - Pymetrics' Bias-Free Algorithms: Pymetrics, an AI-driven hiring platform, faced oscience-based candidate assessment tools
