# Discussion of Findings

The findings of this study underscore the substantial challenges AI-driven hiring systems pose for individuals with disabilities, with AI frequently replicating historical biases and failing to accommodate diverse needs. The analysis of AI hiring tools, including video interviews and resume screeners, reveals a consistent pattern of discrimination due to the limited adaptive measures and biased training data.

8

.

These findings align with previous studies, such as Ajunwa (2021) and Kaminski (2023), which highlight how opaque AI decision-making processes disproportionately affect marginalized job seekers. Similarly, case studies such as Derek Mobley v. Workday Inc. (2024) and HireVue’s AI interview modifications illustrate the tangible consequences of deploying biased hiring tools (Ajunwa, 2021). However, this study extends the discussion by integrating emerging policy interventions, such as New York City’s Bias Audit Law, and global regulatory frameworks like the European Union’s AI Act (2024).

A key implication of these results is the need for Explainable AI (XAI) technologies to ensure transparency in AI-driven hiring. Previous research (Hickman et al., 2024; Hofeditz et al., 2022) emphasizes AI models must offer interpretability for candidates and regulators to understand hiring decisions. Additionally, bias audits, as suggested by Binns and Kirkham (2021), should become a standardized practice to mitigate discriminatory outcomes. By contextualizing these findings within the existing literature and emerging legal frameworks, this study contributes to the ongoing discussion on the ethical application of AI in hiring.