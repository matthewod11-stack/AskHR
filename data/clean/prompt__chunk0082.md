# with a temperature of 0.

NOTE: With more freedom (higher temperature, top-K, top-P, and output tokens), the LLM

might generate text that is less relevant.

WARNING: Have you ever seen a response ending with a large amount of (cid:450)ller words? This is also known as the "repetition loop bug", which is a common issue in Large Language

Models where the model gets stuck in a cycle, repeatedly generating the same ((cid:450)ller) word,

phrase, or sentence structure, o(cid:454)en exacerbated by inappropriate temperature and top-k/