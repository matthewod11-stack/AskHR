# Technologies

A primary concern for AI developers and companies here is imbalances

in data that could create harm. Developers should consider: 1) seeking

out datasets that are representative of the populations they seek to

serve, 2) checking the distribution of potential sources of bias and

alternative demographic attributes in the training data, and 3) using

metrics such as disparate impact to measure outcome disparity between

groups, or equalized odds to ensure that a model’s predictions are

equally accurate across diﬀerent protected groups.

Companies can also turn to available tools, such as IBM’s AI Fairness

360 Toolkit or open-source tools, such as Fairlearn, as they pursue such